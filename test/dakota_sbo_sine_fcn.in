# DAKOTA INPUT FILE - dakota_sbo_sine_fcn.in

# Demonstrates the use of approximation models and a trust region
# optimization strategy in minimizing a "quasi-sinusoidal" function
# that has many local minima. The global optimum is at the point
# (x1,x2) = (0.177,0.177) which has a function value of 0.060.

# Note: This "surrogate-based optimization" (SBO) strategy is not
# guaranteed to converge to the global optimum.  Rather, it is
# intended to smooth out some of the numerical noise (i.e., local
# optima) during the optimization history and to get "close" to the
# global optimum.

# Each DAKOTA test file is capable of running multiple tests. The
# manual process for doing this is to add or uncomment specific lines
# needed for a test and comment out other lines which are not needed
# for that specific test.  Within the automatic test script, a special
# syntax is used to automatically determine which lines are to be used
# for a specific test. A #n (0 - 9) is used to associate lines in the
# test file with a specific test.  The #0 is used to designate lines
# which are to be run as part of the baseline test but not part of the
# other tests. To add multiple tests to a file add the #n to the
# trailing comment of a line, the dakota_test script will parse
# through the file uncommenting the lines marked for a specific test,
# and commenting out unneeded lines marked with the #0. Specific lines
# can be included in multiple tests by adding multiple #n designaters
# seperated by a comma.

# Note on testing in this file:
# These tests exercise the sample point reuse feature of the surrogate
# based optimization strategy. Here, the options are "none," "region," or
# "all," where "none" is the default setting which occurs when the
# "reuse_samples" command is omitted.

strategy,
	single_method
#	graphics
	method_pointer = 'SBLO'

method,
	id_method = 'SBLO'
	surrogate_based_local
	model_pointer = 'SURROGATE'
	approx_method_pointer = 'NLP'
	max_iterations = 100,
	soft_convergence_limit = 10
	trust_region
	  initial_size = 0.20
#	  contraction_factor = 0.50
#	  expansion_factor   = 1.50

method,
	id_method = 'NLP'
	conmin_frcg
#	optpp_cg
#	npsol
#	dot_bfgs
#	dot_frcg
	  max_iterations = 50,
	  convergence_tolerance = 1e-12

model,
	id_model = 'SURROGATE'
	surrogate global
	  responses_pointer = 'SURROGATE_RESP'
	  dace_method_pointer = 'SAMPLING'
#	  reuse_samples region	 	  	#1
#	  reuse_samples all		  	#2
#	  correction multiplicative zeroth_order
#	  use_derivatives
#	  neural_network
	  polynomial quadratic	#(linear/quad/cubic)
#	  kriging
#	    correlations 1.0 1.0
#	  mars
# 	surrogate local taylor_series
#	  actual_model_pointer = 'TRUTH'

variables,
	continuous_design = 2
	  initial_point   -0.3     -0.3
	  lower_bounds    -1.0     -1.0
	  upper_bounds     1.0 	1.0
	  descriptors      'x1'     'x2'

responses,
	id_responses = 'SURROGATE_RESP'
	num_objective_functions = 1
# 	analytic_gradients
#	no_gradients
  	numerical_gradients
  	  method_source dakota
  	  interval_type forward
  	  fd_gradient_step_size = .0001
#	analytic_hessians
	no_hessians

###############################################
# SAMPLING method specifications for building #
# surrogate function(s).		      #
###############################################
method,
	id_method = 'SAMPLING'
	model_pointer = 'TRUTH'
#	dace central_composite
#	dace box_behnken
	dace lhs
	  seed = 123
	  samples = 10
#	dace oas seed = 5
#	  samples = 49 symbols = 7

model,
	id_model = 'TRUTH'
	single
	  interface_pointer = 'TRUE_FN'
	  responses_pointer = 'TRUE_RESP'

interface,
	system #asynchronous
	id_interface = 'TRUE_FN'
 	  analysis_driver =    'quasi_sine_fcn'

responses,
	id_responses = 'TRUE_RESP'
	num_objective_functions = 1
	no_gradients
#	analytic_gradients
#  	numerical_gradients
#  	  method_source dakota
#  	  interval_type forward
#  	  fd_gradient_step_size = .0001
	no_hessians
