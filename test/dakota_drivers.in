#@ p0: MPIProcs=3
#@ p1: MPIProcs=6
#@ p2: MPIProcs=6
#@ p3: MPIProcs=3
#@ p4: MPIProcs=6
#@ p5: MPIProcs=2
#@ p6: MPIProcs=4
#@ p7: MPIProcs=2
#@ p8: MPIProcs=3
#@ p9: MPIProcs=6
#@ p10: MPIProcs=2
# DAKOTA INPUT FILE - dakota_drivers.in

# A multilevel parallel study with concurrency in analysis drivers.
# For one level of parallelism (1 evaluation_server, serial analyses),
# running on 3 processors is a good choice.  For two levels of
# parallelism (1 evaluation_server, 2 processors_per_analysis), a total
# of 6 processors works well.  And for three levels of parallelism,
# 13, 19, 31, or 54 processors could be used for 2, 3, 5, or 9
# evaluation_servers, where 13/19/31 use self-scheduling at the
# iterator level and 54 uses static scheduling at the iterator level.

# Each DAKOTA test file is capable of running multiple tests. The
# manual process for doing this is to add or uncomment specific lines
# needed for a test and comment out other lines which are not needed
# for that specific test.  Within the automatic test script, a special
# syntax is used to automatically determine which lines are to be used
# for a specific test. A #n (0 - 9) is used to associate lines in the
# test file with a specific test.  The #s0 is used to designate lines
# which are to be run as part of the baseline test but not part of the
# other tests. To add multiple tests to a file add the #n to the
# trailing comment of a line, the dakota_test script will parse
# through the file uncommenting the lines marked for a specific test,
# and commenting out unneeded lines marked with the #s0. Specific lines
# can be included in multiple tests by adding multiple #n designaters
# seperated by a comma.

# This tester fills out a test matrix of direct/fork/system interfaces
# vs. synch/asynch local/message passing/hybrid modes.  For serial
# executions (tests 0-6), the 4 combinations of synch/asynch
# evaluations/analyses are tested for each of the interfaces for which
# the combinations are supported.  For parallel executions, the direct
# interface is tested in message-passing mode in tests p0-p2, the fork
# interface is tested in message-passing mode in tests p3-p4 and in
# hybrid mode in tests p5-p7, and the system interface is tested in
# message-passing mode in tests p8-p9 and in hybrid mode in test p10.

# Processor specification for automated parallel tests:
# p0=3, p1=6, p2=6, p3=3, p4=6, p5=2, p6=4, p7=2, p8=3, p9=6, p10=2

method,
	npsol_sqp
	  convergence_tolerance = 1.e-8

variables,
	continuous_design = 4
	  initial_point       1.0 1.0 1.0 1.0

interface,
	direct 				    	    #s0,#p0,#p1,#p2
#	fork 			   #s1,#s2,#s3,#s4,#p3,#p4,#p5,#p6,#p7
#	system					#s5,#s6,#p8,#p9,#p10
#	  asynchronous		      #s2,#s3,#s4,#s6,#p5,#p6,#p7,#p10
#	    evaluation_concurrency = 5 	     #s2,#s4,#s6,#p5,#p7,#p10
#	    evaluation_concurrency = 1 			    #s3,#p6
#	    analysis_concurrency = 3		     #s3,#s4,#p6,#p7
#	    analysis_concurrency = 1		    #s2,#s6,#p5,#p10
	  analysis_drivers = 'text_book1' 'text_book2' 'text_book3'
#	  analysis_components = 'M1' 'M2' 'M3'
#	  evaluation_servers = 1		   #p0,#p1,#p3,#p8
#	  evaluation_servers = 2		       #p2,#p4,#p9
#	  evaluation_scheduling peer dynamic	       #p2,#p4,#p9
#	  processors_per_analysis = 2	 	 	       #p1

responses,
	objective_functions = 1
	nonlinear_inequality_constraints = 2
	numerical_gradients
	  method_source dakota
	  interval_type central
	  fd_gradient_step_size = 1.e-4
	no_hessians
