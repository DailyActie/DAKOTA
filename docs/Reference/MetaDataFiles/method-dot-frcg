Blurb::
A conjugate gradient optimization method
Description::
We here provide a caution regarding \c dot_frcg.  In DOT
Version 4.20, we have noticed inconsistent behavior of this algorithm
across different versions of Linux.  Our best assessment is that it is
due to different treatments of uninitialized variables.  As we do not
know the intention of the code authors and maintaining DOT source code
is outside of the %Dakota project scope, we have not made nor are we
recommending any code changes to address this.  However, all users who
use \c dot_frcg in DOT Version 4.20 should be aware that
results may not be reliable.

The method independent controls for \c max_iterations and \c
max_function_evaluations limit the number of major iterations and the
number of function evaluations that can be performed during a DOT
optimization. The \c convergence_tolerance control defines the
threshold value on relative change in the objective function that
indicates convergence. This convergence criterion must be satisfied
for two consecutive iterations before DOT will terminate. The \c
constraint_tolerance specification defines how tightly constraint
functions are to be satisfied at convergence. The default value for
DOT constrained optimizers is 0.003. Extremely small values for
constraint_tolerance may not be attainable. The output verbosity
specification controls the amount of information generated by DOT: the
\c silent and \c quiet settings result in header information, final
results, and objective function, constraint, and parameter information
on each iteration; whereas the \c verbose and \c debug settings add
additional information on gradients, search direction, one-dimensional
search results, and parameter scaling factors. DOT contains no
parallel algorithms which can directly take advantage of concurrent
evaluations. However, if \c numerical_gradients with \c method_source
\c dakota is specified, then the finite difference function
evaluations can be performed concurrently (using any of the parallel
modes described in the Users Manual [\ref UsersMan "Adams et al., 2010"]). 
In addition, if \c speculative
is specified, then gradients (\c dakota \c numerical or \c analytic
gradients) will be computed on each line search evaluation in order to
balance the load and lower the total run time in parallel optimization
studies. Lastly, specialized handling of linear constraints is
supported with DOT; linear constraint coefficients, bounds, and
targets can be provided to DOT at start-up and tracked
internally. 

Topics::	package_dot, conjugate_gradient, not_yet_reviewed
Examples::
Theory::
Faq::
See_Also::	method-dot-bfgs, method-dot-mmfd, method-dot-slp, method-dot-sqp
