Blurb::
Uncertainty quantification using polynomial chaos expansions
Description::
Groups 1 and 2, plus the optional keywords \c p_refinement and
\c fixed_seed relate 
to the specification of a PCE method. In addition, this method
treats variables that are not aleatoric-uncertain different,
despite the \ref method-active keyword.

Group 3, and the remainder of the optional keywords relate 
to the output of the method.
 
<b> polynomial_chaos Group 1 </b>

Group 1 keywords are used to select the type of basis,
\f$\Psi_i\f$, of the expansion. Three approaches
may be employed:
\li Extended (default if no option is selected)
\li Wiener
\li Askey

The selection of Wiener versus Askey versus
Extended is partially automated and partially under the user's
control. 
- The Extended option is the default and supports only
 Gaussian correlations. <!--- This default can
 be overridden by the user by supplying the keyword \c askey to request
 restriction to the use of Askey bases only or by supplying the keyword
 \c wiener to request restriction to the use of exclusively Hermite
 bases. --> 
- If needed to support prescribed correlations (not under user
 control), the Extended and Askey options will fall back to the Wiener
 option <EM>on a per variable basis</EM>. If the prescribed
 correlations are also unsupported by Wiener expansions, then %Dakota
 will exit with an error. 
- The Extended option avoids the use of any nonlinear
 variable transformations by augmenting the Askey approach with
 numerically-generated orthogonal polynomials for non-Askey probability
 density functions. 
- Extended polynomial selections replace each of the sub-optimal Askey 
 basis selections with numerically-generated polynomials that are 
 orthogonal to the prescribed probability density functions (for bounded 
 normal, lognormal, bounded lognormal, loguniform, triangular, gumbel, 
 frechet, weibull, and bin-based histogram).

<b> polynomial_chaos Group 2 </b>

!!!!!!!!!! These do not match the specification, making this very difficult to parse and use!!!!!!!!!!!!!!

To obtain the coefficients \f$\alpha_i\f$ of the expansion, six
options are provided:

<ul>
 <li> multidimensional integration by a tensor-product of Gaussian
    quadrature rules (specified with \c quadrature_order, and, 
 <li> multidimensional integration by the Smolyak sparse grid method
    (specified with \c sparse_grid_level and, optionally, \c
 <li> multidimensional integration by Stroud cubature rules 
 and extensions as specified with \c cubature_integrand. 
 <li> multidimensional integration by Latin hypercube sampling
    (specified with \c expansion_samples).
 <ul>
  <li> linear regression (specified with either \c collocation_points or
     \c collocation_ratio).
  <li> coefficient import from a file (specified with \c
     expansion_import_file). A total-order expansion is assumed and
     must be specified using \c expansion_order.
 </ul>
</ul>

<b> Active Variables </b>

The default behavior is to form expansions over aleatory 
uncertain continuous variables. To form expansions 
over a broader set of variables, one needs to specify 
\c active followed by \c state, \c epistemic, \c design, or \c all 
in the variables specification block. 

For continuous design, continuous state, and continuous
epistemic uncertain variables included in the expansion,
Legendre chaos bases are used to model the bounded intervals for these
variables. However, these variables are not assumed to have any
particular probability distribution, only that they are independent
variables. Moreover, when probability integrals are evaluated, only
the aleatory random variable domain is integrated, leaving behind a
polynomial relationship between the statistics and the remaining
design/state/epistemic variables.



<b> polynomial_chaos Group 3 </b>

These two keywords are used to specify how this method outputs the
covariance of the responses.


<b> Optional Keywords regarding method outputs </b>

Each of
these sampling specifications refer to sampling on the PCE
approximation for the purposes of generating approximate statistics.
\li \c sample_type
\li \c samples
\li \c seed
\li \c fixed_seed
\li \c rng
\li \c probability_refinement 
\li \c reliability_levels
\li \c response_levels
\li \c probability_levels
\li \c gen_reliability_levels

which should be distinguished from simulation sampling for generating
the PCE coefficients as described in options 4 and 5 above (although
options 4 and 5 will share the \c sample_type, \c seed, and \c rng
settings, if provided). 

The \c probability_refinement specification is
similar to that of \ref MethodNonDLocalRel, with the difference that
the number of refinement samples is not under the user's control
(these evaluations are approximation-based, so management of this
expense is less critical). This option allows for refinement of
probability and generalized reliability results using importance
sampling.

<b> Multi-fidelity UQ </b>

The advanced use case of multifidelity UQ automatically becomes active
if the model selected for iteration by the method specification is a
multifidelity surrogate model (refer to \ref ModelSurrH). In this
case, an expansion will first be formed for the model discrepancy (the
difference between response results if \c additive \c correction or
the ratio of results if \c multiplicative \c correction), using the
first \c quadrature_order or \c sparse_grid_level value along with any
specified refinement strategy. Second, an expansion will be formed
for the low fidelity surrogate model, using the second \c
quadrature_order or \c sparse_grid_level value (if present; the first
is reused if not present) along with any specified refinement
strategy. Then the two expansions are combined (added or multiplied)
into an expansion that approximates the high fidelity model, from
which the final set of statistics are generated. For polynomial chaos
expansions, this high fidelity expansion can differ significantly in 
form from the low fidelity and discrepancy expansions, particularly in
the \c multiplicative case where it is expanded to include all of the
basis products.


Topics::	not_yet_reviewed, problem
Examples::
Theory::
The polynomial chaos expansion (PCE) is a general framework for
the approximate representation of random response functions in terms
of finite-dimensional series expansions in standardized random variables

\f[R = \sum_{i=0}^P \alpha_i \Psi_i(\xi) \f]

where \f$\alpha_i\f$ is a deterministic coefficient, \f$\Psi_i\f$ is a
multidimensional orthogonal polynomial and \f$\xi\f$ is a vector of
standardized random variables. An important distinguishing feature of
the methodology is that the functional relationship between random
inputs and outputs is captured, not merely the output statistics as in
the case of many nondeterministic methodologies. %Dakota provides
access to PCE methods through the NonDPolynomialChaos class. Refer to
the Uncertainty Quantification Capabilities chapter of the Users
Manual [\ref UsersMan "Adams et al., 2010"] for additional information
on the PCE algorithm.

If \e n is small (e.g., two or three), then tensor-product Gaussian
quadrature is quite effective and can be the preferred choice. For
moderate to large \e n (e.g., five or more), tensor-product quadrature
quickly becomes too expensive and the sparse grid and regression
approaches are preferred. <!-- For large \e n (e.g., more than ten),
point collocation may begin to suffer from ill-conditioning and sparse
grids are generally recommended. --> Random sampling for coefficient
estimation is generally not recommended due to its slow convergence
rate. <!--, although it does hold the advantage that the simulation
budget is more flexible than that required by the other approaches.-->
For incremental studies, approaches 4 and 5 support reuse of previous
samples through the \c incremental_lhs (refer to \ref MethodNonDMC for
description of incremental LHS) and \c reuse_samples (refer to \ref
ModelSurrG for description of the "all" option of sample reuse)
specifications, respectively.

In the quadrature and sparse grid cases, growth rates for nested and
non-nested rules can be synchronized for consistency. For a
non-nested Gauss rule used within a sparse grid, linear
one-dimensional growth rules of \f$m=2l+1\f$ are used to enforce odd
quadrature orders, where \e l is the grid level and \e m is the number
of points in the rule. The precision of this Gauss rule is then
\f$i=2m-1=4l+1\f$. For nested rules, order growth with level is
typically exponential; however, the default behavior is to restrict
the number of points to be the lowest order rule that is available
that meets the one-dimensional precision requirement implied by either
a level \e l for a sparse grid (\f$i=4l+1\f$) or an order \e m for a
tensor grid (\f$i=2m-1\f$). This behavior is known as "restricted
growth" or "delayed sequences." To override this default behavior in
the case of sparse grids, the \c unrestricted keyword can be used; it
cannot be overridden for tensor grids using nested rules since it also
provides a mapping to the available nested rule quadrature orders. An
exception to the default usage of restricted growth is the \c
dimension_adaptive \c p_refinement \c generalized sparse grid case
described previously, since the ability to evolve the index sets of a
sparse grid in an unstructured manner eliminates the motivation for
restricting the exponential growth of nested rules.

Faq::
See_Also::	method-adaptive_sampling, method-gpais, method-local_reliability, method-global_reliability, method-sampling, method-importance_sampling, method-stoch_collocation
