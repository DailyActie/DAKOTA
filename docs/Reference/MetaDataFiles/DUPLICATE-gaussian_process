Blurb::
Use a Gaussian Process surrogate or emulator
Description::
This specifies the use of a Gaussian process emulator (also called 
surrogate or meta-model). The Gaussian process (GP) will be constructed using a 
limited number of expensive simulation runs. 

There are two alternative Gaussian 
processes currently available: one that is in the surrogate library called surfpack, 
and one that is in dakota. The surfpack GP is often more accurate but is slower to build.

Kriging/Gaussian-Process Spatial Interpolation Models
\label{models:surf:kriging}
In Dakota 5.2, we have 2 versions of spatial interpolation models.
One is located in Dakota itself and the other in the Surfpack subpackage 
of Dakota which can be compiled in a stand alone mode. These models
are denoted as \c kriging dakota and \c kriging surfpack or 
as \c gaussian_process dakota and 
\c gaussian_process surfpack. In prior Dakota releases, the 
\c dakota version was referred to as the \c gaussian_process 
model while the \c surfpack version was referred to as the 
\c kriging model. As of DAKTOA 5.2, specifying only 
\c gaussian_process or \c kriging will default to the
\c surfpack version in all contexts except Bayesian calibration. 
For now, both versions are supported but the \c dakota version is 
deprecated and intended to be removed in a future release. The two 
\c kriging or \c gaussian_process models are very similar: 
the differences between them are explained in more detail below.

The Kriging, also known as Gaussian process (GP), method uses techniques 
developed in the geostatistics and spatial statistics communities 
( \ref{Cre91}, \ref{Koe96}) to produce smooth surface fit models of the 
response values from a set of data points. The number of times the 
fitted surface is differentiable will depend on the correlation function 
that is used. Currently, the Gaussian correlation function is the only 
option for either version included in Dakota; this makes the GP model 
$C^{\infty}$-continuous. The form of the GP model is

\begin{equation}
 \hat{f}(\underline{x}) \approx \underline{g}(\underline{x})^T\underline{\beta} +
 \underline{r}(\underline{x})^{T}\underline{\underline{R}}^{-1}(\underline{f}-\underline{\underline{G}}\ \underline{\beta})
 \label{models:surf:equation08}
\end{equation}

where $\underline{x}$ is the current point in $n$-dimensional parameter
space; $\underline{g}(\underline{x})$ is the vector of trend basis 
functions evaluated at $\underline{x}$; $\underline{\beta}$ is a vector
containing the generalized least squares estimates of the trend basis 
function coefficients; $\underline{r}(\underline{x})$ is the correlation 
vector of terms between $\underline{x}$ and the data points;
$\underline{\underline{R}}$ is the correlation matrix for all of the 
data points; $\underline{f}$ is the vector of response values; and 
$\underline{\underline{G}}$ is the matrix containing the trend basis 
functions evaluated at all data points. The terms in the correlation 
vector and matrix are computed using a Gaussian correlation function 
and are dependent on an $n$-dimensional vector of correlation parameters,
$\underline{\theta} = \{\theta_{1},\ldots,\theta_{n}\}^T$. By default, 
Dakota determines the value of $\underline{\theta}$ using a Maximum
Likelihood Estimation (MLE) procedure. However, the user can also opt 
to manually set them in the \c gaussian_process surfpack
model by specifying a vector of correlation lengths, 
$\underline{l}=\{\l_{1},\ldots,\l_{n}\}^T$ where 
$\theta_i=1/(2 l_i^2)$. This definition of correlation lengths makes 
their effect on the GP model's behavior directly analogous to the 
role played by the standard deviation in a normal (a.k.a. Gaussian) 
distribution. In the \c gaussian_process surpack model, we used 
this analogy to define a small feasible region in which to search for 
correlation lengths. This region should (almost) always contain some 
correlation matrices that are well conditioned and some that are optimal, 
or at least near optimal. More details on Kriging/GP models may be 
found in \ref{Giu98}.

Since a GP has a hyper-parametric error model, it can be used 
to model surfaces with slope discontinuities along with multiple 
local minima and maxima. GP interpolation is useful for both 
SBO and OUU, as well as for studying the global response value trends 
in the parameter space. This surface fitting method needs a 
minimum number of design points equal to the sum of the number of 
basis functions and the number of dimensions, $n$, but it is 
recommended to use at least double this amount.
%$n_{c_{quad}}$ design points when possible (refer to
%Section \ref{models:surf:polynomial} for $n_{c}$ definitions).

The GP model is guaranteed to pass through all of the response 
data values that are used to construct the model. Generally, this is a
desirable feature. However, if there is considerable numerical noise
in the response data, then a surface fitting method that provides some
data smoothing (e.g., quadratic polynomial, MARS) may be a better
choice for SBO and OUU applications. Another feature of the GP
model is that the predicted response values, $\hat{f}(\underline{x})$,
decay to the trend function, 
$\underline{g}(\underline{x})^T\underline{\beta}$, when $\underline{x}$ 
is far from any of the data points from which the GP model was 
constructed (i.e., when the model is used for extrapolation). 

As mentioned above, there are two \c gaussian_process models 
in Dakota 5.2, the \c surfpack version and the \c dakota
version. More details on the \c gaussian_process dakota
model can be found in \ref{McF08}. The differences between these 
models are as follows: 

\begin{itemize}
\item Trend Function: The GP models incorporate a parametric trend 
   function whose purpose is to capture large-scale variations. In 
   both models, the trend function can be a constant, linear,or 
   reduced quadratic (main effects only, no interaction terms) 
   polynomial. This is specified by the keyword \c trend
   followed by one of \c constant, \c linear, or 
   \c reduced_quadratic (in Dakota 5.0 and earlier, the reduced 
   quadratic option for the \c dakota version was selected using 
   the keyword, \c quadratic). The \\
   \c gaussian_process surfpack model has the additional option 
   of a full (i.e. it includes interaction terms) quadratic polynomial; 
   this is accessed by following the \c trend keyword with 
   \c quadratic.
\item Correlation Parameter Determination: Both of the 
   \c gaussian_process models use a Maximum Likelihood Estimation 
   (MLE) approach to find the optimal values of the hyper-parameters 
   governing the mean and correlation functions. By default both models 
   use the global optimization method called DIRECT, although they search 
   regions with different extents. For the 
   \c gaussian_process dakota model, DIRECT is the only option. 
   The \c gaussian_process surfpack model has several options for 
   the optimization method used. These are specified by the 
   \c optimization_method keyword followed by one of these strings:
   \begin{itemize}
   \item \c global which uses the default DIRECT optimizer,
   \item \c local which uses the CONMIN optimizer,
   \item \c sampling which generates several random guesses and 
      picks the candidate with greatest likelihood, and
   \item \c none 
   \end{itemize} 
   The \c none option, and the starting location of the 
   \c local optimization, default to the center, in 
   log(correlation length) scale, of the of small feasible region. 
   However, these can also be user specified with the 
   \c correlation_lengths keyword followed by a list of $n$ real 
   numbers. The total number of evaluations of the 
   \c gaussian_process surfpack model's likelihood function can 
   be controlled using the \c max_trials keyword followed by a 
   positive integer. Note that we have found the \c global 
   optimization method to be the most robust.
\item Ill-conditioning. One of the major problems in determining 
   the governing values for a Gaussian process or Kriging model is 
   the fact that the correlation matrix can easily become 
   ill-conditioned when there are too many input points close together.
   Since the predictions from the Gaussian process model involve 
   inverting the correlation matrix, ill-conditioning can lead to poor 
   predictive capability and should be avoided. The 
   \c gaussian_process surfpack model defines a small feasible 
   search region for correlation lengths, which should (almost) always 
   contain some well conditioned correlation matrices. In Dakota 5.1, 
   the \c kriging (now \c gaussian_process surfpack or
   \c kriging surfpack) model avoided 
   ill-conditioning by explicitly excluding poorly conditioned 
   $\underline{\underline{R}}$ from consideration on the basis of their 
   having a large (estimate of) condition number; this constraint acted 
   to decrease the size of admissible correlation lengths. Note that a
   sufficiently bad sample design could require correlation lengths to 
   be so short that any interpolatory Kriging/GP model would become 
   inept at extrapolation and interpolation. \\ \\
   The \c gaussian_process dakota model has two features to 
   overcome ill-conditioning. The first is that the algorithm will 
   add a small amount of noise to the diagonal elements of the matrix 
   (this is often referred to as a ``nugget'') and sometimes this is 
   enough to improve the conditioning. The second is that the user 
   can specify to build the GP based only on a subset of points. The 
   algorithm chooses an ``optimal'' subset of points (with respect to 
   predictive capability on the remaining unchosen points) using a 
   greedy heuristic. This option is specified with the keyword 
   \c point_selection in the input file.\\ \\
   As of Dakota 5.2, the \c gaussian_process surfpack model has 
   a similar capability. Points are {\bf not} discarded prior to the 
   construction of the model. Instead, within the maximum likelihood 
   optimization loop, when the correlation matrix violates the 
   explicit (estimate of) condition number constraint, the 
   \c gaussian_process surfpack model will perform a pivoted 
   Cholesky factorization of the correlation matrix. A bisection search 
   is then used to efficiently find the last point for which the 
   reordered correlation matrix is not too ill-conditioned. Subsequent 
   reordered points are excluded from the GP/Kriging model for the 
   current set of correlation lengths, i.e. they are not used to 
   construct this GP model or compute its likelihood. When necessary, 
   the \c gaussian_process surfpack model will automatically 
   decrease the order of the polynomial trend function. Once the 
   maximum likelihood optimization has been completed, the subset of 
   points that is retained will be the one associated with the most 
   likely set of correlation lengths. Note that a matrix being 
   ill-conditioned means that its rows or columns contain a significant 
   amount of duplicate information. Since the points that were 
   discarded were the ones that contained the least unique information, 
   they should be the ones that are the easiest to predict and provide 
   maximum improvement of the condition number. However, the 
   \c gaussian_process surfpack model is not guaranteed to 
   exactly interpolate the discarded points. Warning: when two very 
   nearby points are on opposite sides of a discontinuity, it is 
   possible for one of them to be discarded by this approach.\\ \\
   Note that a pivoted Cholesky factorization can be significantly
   slower than the highly optimized implementation of non-pivoted 
   Cholesky factorization in typical LAPACK distributions. A 
   consequence of this is that the \c gaussian_process surfpack
   model can take significantly more time to build than the 
   \c gaussian_process dakota version. However, tests indicate
   that the \c gaussian_process surfpack version will often be
   more accurate and/or require fewer evaluations of the true function 
   than the \c gaussian_process dakota. For this reason, the
   \c gaussian_process surfpack version is the default 
   option as of Dakota 5.2. 
\item Gradient Enhanced Kriging (GEK). As of Dakota 5.2, the 
   \c use_derivatives keyword will cause the 
   \c gaussian_process surfpack model to be built from a 
   combination of function value and gradient information. The 
   \c gaussian_process dakota model does not have this 
   capability. Incorporating gradient information will only be 
   beneficial if accurate and inexpensive derivative information is 
   available, and the derivatives are not infinite or nearly so. Here 
   ``inexpensive'' means that the cost of evaluating a function value 
   plus gradient is comparable to the cost of evaluating only the 
   function value, for example gradients computed by analytical, 
   automatic differentiation, or continuous adjoint techniques. It is 
   not cost effective to use derivatives computed by finite differences.
   In tests, GEK models built from finite difference derivatives were 
   also significantly less accurate than those built from analytical 
   derivatives. Note that GEK's correlation matrix tends to have a 
   significantly worse condition number than Kriging for the same 
   sample design.\\ \\
   This issue was addressed by using a pivoted Cholesky 
   factorization of Kriging's correlation matrix (which is a small 
   sub-matrix within GEK's correlation matrix) to rank points by how 
   much unique information they contain. This reordering is then 
   applied to whole points (the function value at a point immediately 
   followed by gradient information at the same point) in GEK's 
   correlation matrix. A standard non-pivoted Cholesky is then 
   applied to the reordered GEK correlation matrix and a bisection 
   search is used to find the last equation that meets the constraint on 
   the (estimate of) condition number. The cost of performing pivoted
   Cholesky on Kriging's correlation matrix is usually negligible 
   compared to the cost of the non-pivoted Cholesky factorization of 
   GEK's correlation matrix. In tests, it also resulted in more
   accurate GEK models than when pivoted Cholesky or 
   whole-point-block pivoted Cholesky was performed on GEK's 
   correlation matrix.
\end{itemize}



Topics::	not_yet_reviewed
Examples::
Theory::
Faq::
See_Also::	
