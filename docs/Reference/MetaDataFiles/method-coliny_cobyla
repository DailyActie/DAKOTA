Blurb::
Constrained Optimization BY Linear Approximations (COBYLA)
Description::
SCOLIB (formerly known as COLINY) is a collection of nongradient-based
optimizers that support the Common Optimization Library INterface
(COLIN).  SCOLIB optimizers currently include \c coliny_cobyla, \c
coliny_direct, \c coliny_ea, \c coliny_pattern_search and \c
coliny_solis_wets.  (Yes, the input spec still has "coliny" prepended
to the method name.)  Additional SCOLIB information is available from
https://software.sandia.gov/trac/acro.

SCOLIB solvers now support bound constraints and general nonlinear
constraints.  Supported nonlinear constraints include both equality
and two-sided inequality constraints.  SCOLIB solvers do not yet
support linear constraints.  Most SCOLIB optimizers treat constraints
with a simple penalty scheme that adds \c constraint_penalty times the
sum of squares of the constraint violations to the objective function.
Specific exceptions to this method for handling constraint violations
are noted below.  (The default value of \c constraint_penalty is
1000.0, except for methods that dynamically adapt their constraint
penalty, for which the default value is 1.0.)

The method independent controls for \c max_iterations and \c
max_function_evaluations limit the number of major iterations and the
number of function evaluations that can be performed during a SCOLIB
optimization, respectively. The \c convergence_tolerance control
defines the threshold value on relative change in the objective
function that indicates convergence. The \c output verbosity
specification controls the amount of information generated by SCOLIB:
the \c silent, \c quiet, and \c normal settings correspond to minimal
reporting from SCOLIB, whereas the \c verbose setting corresponds to a
higher level of information, and \c debug outputs method
initialization and a variety of internal SCOLIB diagnostics.  The
majority of SCOLIB's methods perform independent function evaluations
that can directly take advantage of %Dakota's parallel
capabilities. Only \c coliny_solis_wets, \c coliny_cobyla, and certain
configurations of \c coliny_pattern_search are inherently serial (see
\ref MethodSCOLIBPS). The parallel methods automatically utilize
parallel logic when the %Dakota configuration supports
parallelism. Lastly, neither \c speculative gradients nor linear
constraints are currently supported with SCOLIB.  Specification detail
for method independent controls is provided in Tables \ref T5d1 "5.1"
through \ref T5d3 "5.3".

Some SCOLIB methods exploit parallelism through the use of %Dakota's
concurrent function evaluations.  The nature of the algorithms,
however, limits the amount of concurrency that can be exploited.  The
maximum amount of evaluation concurrency that can be leveraged by the
various methods is as follows:

\li COBYLA: one
\li DIRECT: twice the number of variables
\li Evolutionary Algorithms: size of the population
\li Pattern Search: size of the search pattern
\li Solis-Wets: one

All SCOLIB methods support the \c show_misc_options optional
specification which results in a dump of all the allowable method
inputs.  Note that the information provided by this command refers to
optimizer parameters that are internal to SCOLIB, and which may differ
from corresponding parameters used by the %Dakota interface.  The \c
misc_options optional specification provides a means for inputing
additional settings supported by the SCOLIB methods but which are not
currently mapped through the %Dakota input specification. Care must be
taken in using this specification; they should only be employed by
users familiar with the full range of parameter specifications
available directly from SCOLIB and understand any differences that
exist between those specifications and the ones available through
%Dakota.

Each of the SCOLIB methods supports the \c solution_target control,
which defines a convergence criterion in which the optimizer will
terminate if it finds an objective function value lower than the
specified target. 

The Constrained Optimization BY Linear Approximations (COBYLA)
algorithm is an extension to the Nelder-Mead simplex algorithm for
handling general linear/nonlinear constraints and is invoked using the
\c coliny_cobyla group specification.  The COBYLA algorithm employs
linear approximations to the objective and constraint functions, the
approximations being formed by linear interpolation at N+1 points in
the space of the variables.  We regard these interpolation points as
vertices of a simplex. The step length parameter controls the size of
the simplex and it is reduced automatically from \c initial_delta to
\c threshold_delta.  One advantage that COBYLA has over many of its
competitors is that it treats each constraint individually when
calculating a change to the variables, instead of lumping the
constraints together into a single penalty function.

COBYLA currently only supports termination based on the \c
max_function_evaluations and \c solution_target specifications.  The
search performed by COBYLA is currently not parallelized.

The \c crossover_type controls what approach is employed for combining
parent genetic information to create offspring, and the \c
crossover_rate specifies the probability of a crossover operation
being performed to generate a new offspring.  The SCOLIB EA method
supports three forms of crossover, \c two_point, \c blend, and \c
uniform, which generate a new individual through combinations of two
parent individuals.  Two-point crossover divides each parent into
three regions, where offspring are created from the combination of the
middle region from one parent and the end regions from the other
parent.  Since the SCOLIB EA does not utilize bit representations of
variable values, the crossover points only occur on coordinate
boundaries, never within the bits of a particular coordinate.  Uniform
crossover creates offspring through random combination of coordinates
from the two parents.  Blend crossover generates a new individual
randomly along the multidimensional vector connecting the two parents.

The \c mutation_type controls what approach is employed in randomly
modifying continuous design variables within the EA population.  Each
of the mutation methods generates coordinate-wise changes to
individuals, usually by adding a random variable to a given coordinate
value (an "offset" mutation), but also by replacing a given coordinate
value with a random variable (a "replace" mutation).  Discrete design
variables are always mutated using the \c offset_uniform method. The
\c mutation_rate controls the probability of mutation being performed
on an individual, both for new individuals generated by crossover (if
crossover occurs) and for individuals from the existing population.
It is the fraction of trial points that are mutated in a given
iteration and therefore must be specified to be between 0 and 1.  When
mutation is performed, all dimensions of each individual are mutated.
The \c mutation_scale specifies a scale factor which scales continuous
mutation offsets; this is a fraction of the total range of each
dimension, so \c mutation_scale is a relative value between 0 and 1.
The \c mutation_range is used to control \c offset_uniform mutation
used for discrete parameters.  The replacement discrete value is the
original value plus or minus an integer value up to \c mutation_range.
The \c offset_normal, \c offset_cauchy, and \c offset_uniform mutation
types are "offset" mutations in that they add a 0-mean random variable
with a normal, cauchy, or uniform distribution, respectively, to the
existing coordinate value.  These offsets are limited in magnitude by
\c mutation_scale.  The \c replace_uniform mutation type is not
limited by \c mutation_scale; rather it generates a replacement value
for a coordinate using a uniformly distributed value over the total
range for that coordinate.

Note that \c mutation_scale and \c mutation_range are not recognized
by %Dakota as valid keywords unless \c mutation_type has been
specified and the type is an "offset" mutations.

The SCOLIB EA method uses self-adaptive mutation, which modifies the mutation
scale dynamically.  This mechanism is borrowed from EAs like 
evolution strategies.  The \c non_adaptive flag can be used to deactivate
the self-adaptation, which may facilitate a more global search.  

Note that \c non_adaptive is not recognized by %Dakota as a valid
keyword unless \c mutation_type has been specified.


Topics::	package_scolib, package_coliny, other_optimization, not_yet_reviewed
Examples::
Theory::
Faq::
See_Also::	method-coliny_beta, method-coliny_direct, method-coliny_pattern_search, method-coliny_ea, method-coliny_solis_wets
