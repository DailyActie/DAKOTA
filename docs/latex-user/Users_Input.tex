\chapter{Inputs to Dakota}\label{input}

\section{Overview of Inputs}\label{input:overview}

Dakota supports a number of command-line arguments, as described in
Section~\ref{tutorial:installation:running}.  Among these are
specifications for the Dakota input file and, optionally, a restart
file.  The syntax of the Dakota input file is described in detail in
the Dakota Reference Manual~\cite{RefMan}, and the restart file is
described in Chapter~\ref{restart}.

A Dakota input file may be prepared with a text editor such as Emacs,
Vi, or WordPad, or with the JAGUAR Dakota graphical user interface.
The JAGUAR Dakota GUI is built on the Java-based Eclipse Framework
\cite{Eclipse} and presents the Dakota input specification options in
synchronized text-editing and graphical views.  JAGUAR includes
templates and wizards for helping create Dakota studies and can invoke
Dakota to run an analysis.  The Dakota GUI for Linux, Windows, and
Mac, is available for download from the Dakota website
\url{http://dakota.sandia.gov/}, along with licensing information,
separate GUI documentation, and installation tips.

\subsection{Tabular Data Formats}\label{input:tabularformat}

The Dakota input file and/or command line may identify additional text
files for tabular data import in contexts described in
Section~\ref{input:import}.  Examples include data from which to build
a surrogate, points at which to run a list parameter study, post-run
input data, and least squares and Bayesian calibration data. Dakota
writes and reads tabular data with C++ stream operators/conversions,
so most integer and floating point formats are acceptable for imported
numeric data.

By default, Dakota tabular import data must be formatted similarly to
its tabular output~\ref{output:tabular}; in an annotated columnar
format.  Annotated tabular input (default for all tabular I/O and
explicitly specified via {\tt annotated}) is given in a text file with
one leading row (header) of comments/column labels and two leading
columns (identifiers), one for evaluation ID and one for interface ID.
These leading labels surround num\_rows x num\_cols of
whitespace-separated numeric data, (newlines separating rows are not
currently required, but may be in the future).  The numeric data in a
row may correspond to variables, variables followed by responses, data
point for calibration, etc., depending on context.  {\bf Notes:}
\begin{enumerate}
\item As of Dakota 6.1, the default/\texttt{annotated} option requires
  two leading columns, one for the evaluation ID and one for the
  interface ID.  This format is shown in Figure~\ref{output:tabcont}.
  Prior to Dakota 6.1, the annotated format required only one leading
  column, but now requires two.

\item Variables should appear in input specification order as
  documented in the reference manual.  As of Dakota 6.1, the annotated
  format requires columns for all of the variables (active and
  inactive), not only the active variables as in previous versions.
  To import data corresponding only to the active variables, use the
  keyword \texttt{active\_only} when specifying the import file.
\end{enumerate}

When optionally specifying \texttt{freeform} for a given tabular
import, the data file must be provided in a free-form format, omitting
the leading one row and two columns. The raw num\_rows x num\_cols
numeric data entries may appear separated with any whitespace
including arbitrary spaces, tabs, and newlines.  In this format,
vectors may therefore appear as a single row or single column (or
mixture; entries will populate the vector in order).

{\bf Attention:} Prior to October 2011, samples, calibration, and
surrogate data files were free-form format.  They now default to
annotated format, though {\tt freeform} remains an option.  For both
formats, a warning will be generated if a specific number of data are
expected, but extra is found and an error generated when there is
insufficient data.  Some TPLs like SCOLIB and JEGA manage their own
file I/O and only support the free-form option.


\section{Data Imports}\label{input:import}

The Dakota input file and/or command line may identify additional
files used to import data into Dakota.

\subsection{AMPL algebraic mappings: stub.nl, stub.row, and stub.col}

As described in Section~\ref{advint:algebraic}, an AMPL
specification of algebraic input-to-output relationships may be
imported into Dakota and used to define or augment the mappings of a
particular interface.

\subsection{Genetic algorithm population import}

Genetic algorithms (GAs) from the JEGA and SCOLIB packages support a
population import feature using the keywords
\texttt{initialization\_type flat\_file = \emph{STRING}}.  This is
useful for warm starting GAs from available data or previous runs.
Refer to the Method Specification chapter in the Dakota Reference
Manual~\cite{RefMan} for additional information on this specification.
The flat file must be in free-form format as described in
Section~\ref{input:tabularformat}.

\subsection{Calibration (least squares) data import}

Deterministic least squares and Bayesian Calibration methods allow
specification of experimental observations to difference with
responses in calculating a model misfit metric (such as a sum of
squared residuals).  The default file format is {\tt annotated}, but
the {\tt freeform} option is supported.  The data file is comprised of
one or more experiments, each with one or more replicates, one row per
replicate.  The columns of the data file contain, in sequence
\begin{itemize}
\item {\bf configuration variables (optional):} state variable values
  indicating the configuration at which this experiment was conducted;
  length must agree with thee number of state variables active in the
  study.
\item {\bf experimental observations (required):} experimental data
  values to difference with model responses; length number of
  responses.
\item {\bf experimental standard deviations (optional):} measurement
  errors (standard deviations) associated with the data; length 1
  (same value for each model response) or num\_responses.
\end{itemize}
See~\ref{nls:examples} and the Dakota Reference Manual Responses
section for further details.

\subsection{PCE coefficient import}

Polynomial chaos expansion (PCE) methods compute coefficients for
response expansions which employ a basis of multivariate orthogonal
polynomials.  Normally, the \texttt{polynomial\_chaos} method
calculates these coefficients based either on a spectral projection or
a linear regression (see Section~\ref{uq:expansion}).  However, Dakota
also supports the option of importing a set of response PCE
coefficients from a file specified with \\
\texttt{import\_expansion\_file = \emph{STRING}}.  Each row of the
file must be comprised of a coefficient followed by its associated
multi-index (the same format used for output described in
Section~\ref{sec:output:pce}).  This file import can be used to
evaluate moments analytically or compute probabilities numerically
from a known response expansion.  Refer to the Method Specification
chapter in the Dakota Reference Manual~\cite{RefMan} for additional
information on this specification.

\subsection{Surrogate construction and evaluation data}

Global data fit surrogates, including some stochastic expansions, may
be constructed from a variety of data sources.  One of these sources
is an auxiliary data file, as specified by the keyword \texttt{import\
  points\_file = \emph{STRING}}.  The file may be in annotated
(default) or free-form format with columns corresponding to variables
and responses.  Surfpack global surrogate models may also be evaluated
at a user-provided file containing \texttt{challenge\_points}.  Refer
to the Model Specification chapter in the Dakota Reference
Manual~\cite{RefMan} for additional information on this specification.

\subsection{Variables/responses import to post-run}

The post-run mode (supported only for sampling, parameter study, and
DACE methods) requires specification of a file containing parameter
and response data in annotated tabular format (see Section
~\ref{input:tabularformat}; free-form is not supported).  Leading
columns for evaluation and interface IDs are followed by columns for
variables (active and inactive by default), then those for responses,
with an ignored header row of labels and then one row per evaluation.
Typically this file would be generated by executing \texttt{dakota -i
  dakota.in -pre\_run ::variables.dat} and then adding columns of
response data to variables.dat to make varsresponses.dat.  The file is
specified at the command line with:
\begin{small}
\begin{verbatim}
    dakota -i dakota.in -post_run varsresponses.dat::
\end{verbatim}
\end{small}

% LocalWords:  WordPad pre num whitespace freeform TPLs SCOLIB JEGA AMPL nl GAs
% LocalWords:  PCE multi dakota dat varsresponses Surfpack
